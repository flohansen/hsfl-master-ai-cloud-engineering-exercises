# Cloud Engineering: Aufgabenblatt 6

## Aufgabe 1: Deployment einer App auf einem (einfachen) Kubernetes-Cluster

Diese √úbung dient als Lernhilfe f√ºr den ersten Kontakt mit Kubernetes (K8S). 

1. Installieren Sie [kubectl](https://kubernetes.io/docs/tasks/tools/) und
   [minikube](https://minikube.sigs.k8s.io/docs/start/) auf Ihrer
   Entwicklungsmaschine.
2. Erstellen Sie mithilfe von minikube ein lokales Cluster mit einem einzigen
   Node und starten Sie es.
3. Erstellen Sie ein Deployment f√ºr einen Ihrer Services mithilfe von `kubectl
   create deployment`.
4. Erstellen Sie einen Service f√ºr Ihre Pods aus 3. mithilfe von `kubectl
   expose`.
5. √Ñndern Sie den Typ des Services auf `NodePort` und `LoadBalancer`. Was sind
   die Unterschiede?
6. Starten Sie das Dashboard von minikube mit `minikube dashboard` und
   validieren Sie Ihr Deployment.
7. Testen Sie die Verf√ºgbarkeit Ihrer Anwendung von au√üerhalb des
   Kubernetes-Netzwerkes (z.B. √ºber die Loopback-IP).
8. Skalieren Sie Ihre Anwendung mithilfe von `kubectl scale` auf 10 Replicas.
9. Validieren Sie wie vorher die Skalierung √ºber das Dashboard und pr√ºfen Sie
   die Verf√ºgbarkeit.

## Aufgabe 2: Erstellen eines Kubernetes-Clusters

> üí° **Information:**
> [Hier](SETUP_CLUSTER.md) finden Sie eine Hilfestellung f√ºr die Einrichtung
> eines Kubernetes-Clusters unter Ubuntu Server 20.04. Alternativ k√∂nnen Sie
> die [offizielle
> Dokumentation](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)
> von kubeadm zum Erstellen eines Kubernetes-Clusters als Unterst√ºtzung lesen.

Nachdem Sie in Aufgabe 1 den ersten Kontakt mit einem Kubernetes-Cluster √ºber
minikube hatten, sollen Sie nun ein eigenes Cluster mit mehreren Nodes
erzeugen. In der Aufgabe wird das Vorgehen mit virtuellen Maschinen
beschrieben. Wenn Sie Zugriff auf entsprechende Hardware besitzen, k√∂nnen Sie
nat√ºrlich auch mit dieser anstelle der virtuellen Maschinen arbeiten.

1. Installieren Sie [VirtualBox](https://www.virtualbox.org/) auf Ihrem
   Host-System und laden Sie sich das [Abbild von Ubuntu Server
   20.04 LTS](https://ubuntu.com/download/server#downloads)
   als ISO-Datei herunter. Achten Sie darauf, dass Sie die Version 20.04
   verwenden, da die Installation von Kubernetes bei neueren Versionen wesentlich
   komplizierter wird.
2. Richten Sie beliebig viele (virtuelle) Maschinen ein und installieren Sie
   Ubuntu 20.04 LTS als Betriebssystem. Eine Maschine wird als Control-Plane
   bzw. Master-Node, die restlichen als Worker-Nodes eingerichtet. Achten Sie bei
   der Verwendung von virtuellen Maschinen auf die zur Verf√ºgung stehenden
   Resourcen des Host-Systems. Der Master-Node sollte mindestens 2 CPU und 2GB
   Arbeitsspeicher besitzen w√§hrend Worker-Nodes mindestens 1 CPU und 1GB
   Arbeitsspeicher besitzen sollten.

   **Beispiel f√ºr ein Cluster mit 5 Maschinen:**

   * 1 Master-Node (Control-Plane)
   * 4 Worker-Nodes

3. Damit Ihr Kubernetes-Cluster Pods (Container) verwalten kann, m√ºssen Sie
   zuerst eine Container-Runtime auf jedem Node installieren. Sie k√∂nnen hierf√ºr
   [containerd](https://github.com/containerd/containerd/blob/main/docs/getting-started.md),
   [CRI-O](https://cri-o.io/) oder [Docker Engine (mit
   cri-dockerd)](https://docs.docker.com/engine/install/ubuntu/)
   verwenden.
4. Installieren Sie [kubectl](https://kubernetes.io/docs/reference/kubectl/kubectl/), [kubelet](https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/) und
   [kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)
   auf jedem der Nodes.
5. Initialisieren Sie einen Ihrer Nodes als Control-Plane mithilfe von kubeadm.
6. Installieren Sie f√ºr die Kommunikation zwischen Container ein
   Container-Network-Interface (CNI) wie
   [calico](https://www.tigera.io/project-calico/) auf dem Control-Plane.
7. Folgen Sie den Anweisungen zum Registrieren Ihrer Worker-Nodes.

## Aufgabe 3: Deployment Ihrer Anwendung

> üí° **Information:**
> [Dieses
> Beispiel](https://kubernetes.io/docs/tasks/access-application-cluster/connecting-frontend-backend/)
> zeigt, wie verschiedene Deployments auf einem Cluster miteinander
> kommunizieren k√∂nnen. Dies ist hilfreich, damit z.B. Frontend-Services mit
> entsprechenden Backend-Services sprechen k√∂nnen.

1. Erstellen Sie Manifests zum Deployen Ihrer Microservices (kind: `Deployment`).
2. Erstellen Sie Manifests f√ºr das Ver√∂ffentlichen Ihrer Microservices mit Kubernetes-Services (kind: `Service`).
3. Deployen Sie Ihre Microservices auf Ihr in Aufgabe 2 erstelltes Cluster.
4. Testen Sie Ihr Deployment, indem Sie auf Ihre Web-Anwendung √ºber den Browser au√üerhalb des Cluster-Netzwerkes zugreifen (z.B. vom Host-System).
